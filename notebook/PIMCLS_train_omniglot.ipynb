{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"PIMCLS_train_omniglot.ipynb","private_outputs":true,"provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMPU/SLlbX6p6yYZa3vaILz"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"dFH5KjwMoU4r"},"source":["#Setup"]},{"cell_type":"code","metadata":{"id":"zZZK0SX9czXB"},"source":["!pip install wandb"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BFT9RuV6TqYD"},"source":["%cd /content\n","!git clone https://github.com/ethan-jiang-1/pim_classification.git pimcls \n","%cd /content/pimcls\n","!git checkout master\n","!git pull origin master\n","!git submodule update --init --recursive\n","%cd /content/pimcls/pim\n","!pip install -e .\n","%cd /content/pimcls"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"QjqYDSAXoZSs"},"source":["#Download dataset - omniglot"]},{"cell_type":"code","metadata":{"id":"VT9z686igj7I"},"source":["import os\n","import time\n","from IPython.display import clear_output\n","import torchvision \n","import shutil\n","from sklearn.model_selection import train_test_split\n","\n","\n","def make_ds_on(char_folder, ds_folder):\n","    os.makedirs(ds_folder, exist_ok=True)\n","    fds = os.listdir(char_folder)\n","    for fd in fds:\n","        fdr = \"{}/{}\".format(char_folder, fd)\n","        if not os.path.isdir(fdr):\n","            continue\n","        fls = os.listdir(fdr)\n","        #print(fdr, fls)\n","        train_fls, val_fls = train_test_split(fls, test_size=0.4)\n","        #print(train_fls)\n","        #print(val_fls)\n","        ds_train = \"{}/train/{}\".format(ds_folder, fd)\n","        os.makedirs(ds_train, exist_ok=True)\n","        for fl in train_fls:\n","            src = \"{}/{}\".format(fdr, fl)\n","            dst = \"{}/{}\".format(ds_train, fl)\n","            shutil.copy(src, dst)\n","\n","        val_fls, test_fls = train_test_split(val_fls, test_size=0.5)\n","        ds_val = \"{}/val/{}\".format(ds_folder, fd)\n","        os.makedirs(ds_val, exist_ok=True)\n","        for fl in val_fls:\n","            src = \"{}/{}\".format(fdr, fl)\n","            dst = \"{}/{}\".format(ds_val, fl)\n","            shutil.copy(src, dst)\n","\n","        ds_test = \"{}/test/{}\".format(ds_folder, fd)\n","        os.makedirs(ds_test, exist_ok=True)\n","        for fl in test_fls:\n","            src = \"{}/{}\".format(fdr, fl)\n","            dst = \"{}/{}\".format(ds_test, fl)\n","            shutil.copy(src, dst)\n","\n","%cd /content/pimcls\n","\n","if not os.path.isdir(\"omniglot_src\"):\n","    ds = torchvision.datasets.Omniglot(\"omniglot_src\", download=True)\n","    ds.download()\n","\n","src_folder = \"/content/pimcls/omniglot_src/omniglot-py/images_background/Burmese_(Myanmar)\"\n","dst_folder = \"/content/pimcls/omniglot_myanmar\"\n","ds_folder = \"/content/pimcls/omniglot\"\n","\n","if not os.path.isdir(dst_folder):\n","    shutil.copytree(src_folder, dst_folder)\n","\n","make_ds_on(dst_folder, ds_folder)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pMRUY1BIocYk"},"source":["#Prepare training"]},{"cell_type":"code","metadata":{"id":"cfyR_VGphAC2"},"source":["cmd = \"\"\"./train.py ../omniglot \n","--model seresnet34 \n","--sched cosine \n","--epochs 80 \n","--warmup-epochs 5 \n","--lr 0.4 \n","--reprob 0.5 \n","--remode pixel \n","--batch-size 8 \n","--amp \n","--log-wandb \n","-j 4\"\"\"\n","\n","cmd_line = cmd.replace(\"\\n\", \"\")\n","print(cmd_line)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_F2otvG2ogKl"},"source":["#Training"]},{"cell_type":"code","metadata":{"id":"uHrGg4NYhO0a"},"source":["%cd /content/pimcls/pim \n","!$cmd_line"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"PTw2u1oj4m8F"},"source":["#Inference"]},{"cell_type":"code","metadata":{"id":"YnLpBSHMOsxm"},"source":["def find_model_src():\n","    output_folder = \"/content/pimcls/pim/output/train\"\n","    dfs = os.listdir(output_folder)\n","    for df in dfs:\n","        result_folder = \"{}/{}\".format(output_folder, df)\n","        model_best_path = \"{}/model_best.pth.tar\".format(result_folder)\n","        if os.path.isfile(model_best_path):\n","            return model_best_path\n","    return None\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"JPn3DcZ55ak3"},"source":["os.makedirs(\"/content/pimcls/model\", exist_ok=True)\n","model_src = find_model_src()\n","model_dst = \"/content/pimcls/model/model_best.pth.tar\"\n","if not os.path.isfile(model_dst): \n","    shutil.copy(model_src, model_dst)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BRz0WtTSSE_B"},"source":["import torch\n","checkpoint = torch.load(model_dst, map_location='cpu')\n","print()\n","print(type(checkpoint))\n","print(checkpoint.keys())\n","print()\n","\n","print(\"epoch  \\t\", checkpoint[\"epoch\"])\n","print(\"arch.  \\t\", checkpoint[\"arch\"])\n","print(\"version\\t\", checkpoint[\"version\"])\n","print(\"metric \\t\", checkpoint[\"metric\"])\n","print(\"args   \\t\",checkpoint[\"args\"])\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZUTdN61BUdCQ"},"source":["from timm.models import create_model\n","\n","model = create_model(\n","    checkpoint[\"arch\"],\n","    num_classes=checkpoint[\"args\"].num_classes,\n","    in_chans=3,\n","    checkpoint_path=model_dst)\n","print(model)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"H8wsa4AeDb6I"},"source":["python inference.py /imagenet/validation/ --model mobilenetv3_large_100 --checkpoint ./output/train/model_best.pth.tar"]},{"cell_type":"code","metadata":{"id":"TS82ZTYj4jAw"},"source":["def do_inference(subfolder_name):\n","    %cd /content/pimcls/pim \n","\n","    output_folder = \"{}\".format(subfolder_name)\n","    print(output_folder)\n","    os.makedirs(output_folder, exist_ok=True)\n","\n","    cmd = \"\"\"./inference.py /content/pimcls/omniglot_myanmar/{} \n","    --model seresnet34 \n","    --checkpoint /content/pimcls/model/model_best.pth.tar \n","    --output_dir {}\n","    \"\"\"\n","\n","    cmd = cmd.format(subfolder_name, subfolder_name)\n","    cmd_line = cmd.replace(\"\\n\", \"\").replace(\"\\t\", \"\")\n","    print(cmd_line)\n","\n","    !$cmd_line"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZQgDogC4l8C"},"source":["do_inference(\"character01\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DaSHMtylX4P4"},"source":["do_inference(\"character02\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_AiTUuvwYBsh"},"source":["do_inference(\"character03\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"IDYPgPwZkFFm"},"source":["do_inference(\"character04\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xZjlegeOkL4I"},"source":["do_inference(\"character34\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3Ao3QolmwQg"},"source":["# model check"]},{"cell_type":"code","metadata":{"id":"CoVow4R7nTld"},"source":["from PIL import Image\n","from timm.data import resolve_data_config\n","from timm.data.transforms_factory import create_transform\n","import torch\n","\n","def get_transform(model):\n","    config = resolve_data_config({}, model=model)\n","    transform = create_transform(**config)\n","    return transform, config\n","\n","def pred_poss(model, img_path):\n","    transform, _ = get_transform(model)\n","\n","    img = Image.open(img_path).convert('RGB')\n","    print(img.height, img.width)\n","    tensor = transform(img).unsqueeze(0)\n","    print(tensor.shape)\n","\n","    with torch.no_grad():\n","        out = model(tensor)\n","    probabilities = torch.nn.functional.softmax(out[0], dim=0)\n","    print(probabilities.shape)\n","    #for ndx, p in enumerate(probabilities):\n","    #  print(ndx, p)\n","\n","    print(\"top5\")\n","    top5_prob, top5_catid = torch.topk(probabilities, 5)\n","    for i in range(top5_prob.size(0)):\n","        print(i, top5_catid[i], top5_prob[i].item())\n","    print()\n","\n","    print(\"top10\")\n","    top10_prob, top10_catid = torch.topk(probabilities, 10)\n","    for i in range(top10_prob.size(0)):\n","        print(i, top10_catid[i], top10_prob[i].item())\n","\n","    return top10_prob, top10_catid"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Jnw1IHMzrPne"},"source":["transform, config = get_transform(model)\n","print(config)\n","print(transform)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9EXHOiFSnYXE"},"source":["pred_poss(model, \"/content/pimcls/omniglot_myanmar/character01/0770_01.png\")"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"GrMkODIhpwgx"},"source":["pred_poss(model, \"/content/pimcls/omniglot_myanmar/character30/0799_04.png\")"],"execution_count":null,"outputs":[]}]}